# Introduction

TinyLLMæ˜¯æˆ‘å­¦ä¹ å¤§è¯­è¨€æ¨¡å‹çš„ä¸€ä¸ªå°é¡¹ç›®ï¼Œç›®æ ‡æ˜¯å°è¯•ä»é›¶å¼€å§‹è®­ç»ƒä¸€ä¸ªéå¸¸è½»é‡çš„è¯­è¨€æ¨¡å‹ã€‚

é¡¹ç›®ç›®å‰åŒ…å«ï¼š

- ä¸€ä¸ªç®€å•çš„æ¨¡å‹å®ç°ï¼ˆåŒ…æ‹¬åŸºç¡€çš„Denseå’ŒMoEç»“æ„ï¼‰
- åŸºæœ¬çš„é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒæµç¨‹
- ä½¿ç”¨äº†ä¸€äº›å¸¸è§çš„å¼€æºæ¡†æ¶ï¼Œå¦‚`transformers`, `accelerate`, `peft`ç­‰
- æ”¯æŒåœ¨å•å¼ å’Œå¤šå¼ GPUä¸Šè®­ç»ƒ
- åŒ…å«äº†ä¸€äº›ç®€å•çš„æ¨¡å‹æµ‹è¯•ä»£ç 

è¿™ä¸ªé¡¹ç›®è®°å½•äº†æˆ‘çš„å­¦ä¹ è¿‡ç¨‹ï¼Œè‚¯å®šè¿˜æœ‰å¾ˆå¤šä¸è¶³å’Œéœ€è¦æ”¹è¿›çš„åœ°æ–¹ã€‚å¸Œæœ›èƒ½å’Œå¤§å®¶ä¸€èµ·äº¤æµå­¦ä¹ ï¼Œå…±åŒè¿›æ­¥ï¼

# Environment

ä»…æ˜¯æˆ‘ä¸ªäººçš„è½¯ç¡¬ä»¶ç¯å¢ƒé…ç½®ï¼Œè‡ªè¡Œé…Œæƒ…æ›´æ”¹ï¼š

* Ubuntu == 22.04
* Python == 3.10
* Pytorch == 2.1.2
* CUDA == 12.1
* [requirements.txt](./requirements.txt)

# Quick Inference & Test

</div>

```bash
# step 1
git clone https://github.com/VocabVictor/tinyllm.git
# or 
git clone https://gh-proxy.com/https://github.com/VocabVictor/tinyllm.git
```

```bash
# step 2
python eval/eval.py
```

æˆ–è€…å¯åŠ¨streamlitï¼Œå¯åŠ¨ç½‘é¡µèŠå¤©ç•Œé¢

```bash
# or step 3, use streamlit
streamlit run inference/fast_inference.py
```

# Quick Start

* 0ã€ç¯å¢ƒé…ç½®
  ```bash
  pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple
  ```
* 1ã€è·å–é¡¹ç›®ä»£ç 
  ```bash
  git clone https://github.com/VocabVictor/tinyllm.git
  # or
  git clone https://gh-proxy.com/https://github.com/VocabVictor/tinyllm.git
  ```
* 2ã€å¦‚éœ€è‡ªè¡Œè®­ç»ƒæ¨¡å‹

    * 2.1 ä»[æŒ‡å®šæ•°æ®é›†åœ°å€](#æ•°æ®é›†ä¸‹è½½åœ°å€)è·å–æ•°æ®é›†å¹¶ç½®äº`./dataset`ç›®å½•

    * 2.2 æ‰§è¡Œ`python data_process.py`å¯¹æ•°æ®é›†è¿›è¡Œå¤„ç†ï¼Œä¾‹å¦‚å¯¹é¢„è®­ç»ƒæ•°æ®è¿›è¡Œtokenç¼–ç ã€ä»SFTæ•°æ®é›†ä¸­æå–é—®ç­”å¯¹è‡³CSVæ–‡ä»¶

    * 2.3 åœ¨`./model/LMConfig.py`ä¸­è°ƒæ•´æ¨¡å‹å‚æ•°é…ç½®
    * 2.4 æ‰§è¡Œ`python pretrain/pretrain.py`è¿›è¡Œé¢„è®­ç»ƒ
    * 2.5 æ‰§è¡Œ`python sft/full_sft.py`è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒ
    * 2.6 æ‰§è¡Œ`python sft/lora_sft.py`è¿›è¡ŒLoRAå¾®è°ƒï¼ˆå¯é€‰ï¼‰
    * 2.7 æ‰§è¡Œ`python rlhf/dpo_train.py`è¿›è¡ŒåŸºäºäººç±»åå¥½çš„å¼ºåŒ–å­¦ä¹ å¯¹é½ï¼ˆå¯é€‰ï¼‰

* 3ã€éªŒè¯æ¨¡å‹æ¨ç†æ•ˆæœ
    * ç¡®ä¿è®­ç»ƒå®Œæˆçš„æ¨¡å‹æƒé‡æ–‡ä»¶ä½äº`./out/`ç›®å½•
       ```text
      out
      â”œâ”€â”€ multi_chat
      â”‚   â”œâ”€â”€ full_sft_512.pth
      â”‚   â”œâ”€â”€ full_sft_512_moe.pth
      â”‚   â””â”€â”€ full_sft_768.pth
      â”œâ”€â”€ single_chat
      â”‚   â”œâ”€â”€ full_sft_512.pth
      â”‚   â”œâ”€â”€ full_sft_512_moe.pth
      â”‚   â””â”€â”€ full_sft_768.pth
      â”œâ”€â”€ pretrain_768.pth
      â”œâ”€â”€ pretrain_512_moe.pth
      â”œâ”€â”€ pretrain_512.pth
      ```
    * æ‰§è¡Œ`python eval/eval_pretrain.py`æµ‹è¯•é¢„è®­ç»ƒæ¨¡å‹çš„æ–‡æœ¬ç”Ÿæˆèƒ½åŠ›
    * æ‰§è¡Œ`python eval/eval.py`æµ‹è¯•æ¨¡å‹çš„å¯¹è¯èƒ½åŠ›

é¢„è®­ç»ƒå’Œå…¨å‚å¾®è°ƒè¿‡ç¨‹ï¼ˆåŒ…æ‹¬pretrainå’Œfull_sftï¼‰å‡æ”¯æŒå¤šGPUå¹¶è¡ŒåŠ é€Ÿè®­ç»ƒã€‚ä»¥ä¸‹æ˜¯åœ¨å•æœºå¤šGPUç¯å¢ƒä¸‹å¯åŠ¨è®­ç»ƒçš„æ–¹æ³•ï¼š

* ä½¿ç”¨åˆ†å¸ƒå¼æ•°æ®å¹¶è¡Œ(DDP)è¿›è¡Œè®­ç»ƒï¼š
  ```bash
  torchrun --nproc_per_node N pretrain/pretrain.py
  torchrun --nproc_per_node N sft/full_sft.py
  ```

* ä½¿ç”¨DeepSpeedæ¡†æ¶è¿›è¡Œè®­ç»ƒï¼š
  ```bash
  deepspeed --master_port 29500 --num_gpus=N pretrain/pretrain.py
  deepspeed --master_port 29500 --num_gpus=N sft/full_sft.py
  ```

æ³¨ï¼šåœ¨ä¸Šè¿°å‘½ä»¤ä¸­ï¼ŒNä»£è¡¨è¦ä½¿ç”¨çš„GPUæ•°é‡ã€‚è¯·æ ¹æ®å®é™…ç¡¬ä»¶é…ç½®è°ƒæ•´è¯¥å‚æ•°ã€‚

* è®°å½•è®­ç»ƒè¿‡ç¨‹
    ```bash
    torchrun --nproc_per_node N pretrain/pretrain.py --use_wandb
    # and
    torchrun --nproc_per_node N sft/full_sft.py --use_wandb
    ```
    é€šè¿‡æ·»åŠ `--use_wandb`å‚æ•°ï¼Œå¯ä»¥è®°å½•è®­ç»ƒè¿‡ç¨‹ï¼Œè®­ç»ƒå®Œæˆåï¼Œå¯ä»¥åœ¨wandbç½‘ç«™ä¸ŠæŸ¥çœ‹è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡ä¿®æ”¹`wandb_project`å’Œ`wandb_run_name`å‚æ•°ï¼Œå¯ä»¥æŒ‡å®šé¡¹ç›®åç§°å’Œè¿è¡Œåç§°ã€‚

# Data sources

- ğŸ¤– åˆ†è¯å™¨ï¼šåˆ†è¯å™¨å°±åƒä¸€æœ¬ç‰¹æ®Šçš„è¯å…¸ï¼Œå®ƒæŠŠå•è¯è½¬æ¢æˆæ•°å­—ã€‚è¿™æ ·åšæ˜¯ä¸ºäº†è®©è®¡ç®—æœºæ›´å®¹æ˜“ç†è§£å’Œå¤„ç†æ–‡å­—ã€‚

  æœ‰ä¸¤ç§æ–¹æ³•å¯ä»¥å¾—åˆ°åˆ†è¯å™¨ï¼š
  1. è‡ªå·±åˆ›å»ºä¸€ä¸ªï¼šå¯ä»¥ç”¨`pretrain/train_tokenizer.py`æ¥åšè¿™ä»¶äº‹ã€‚
  2. ä½¿ç”¨ç°æˆçš„ï¼šç›´æ¥ç”¨å…¶ä»–äººå·²ç»åšå¥½çš„åˆ†è¯å™¨ã€‚

  åˆ†è¯å™¨çš„è¯è¡¨ï¼ˆå°±æ˜¯è¿™æœ¬"è¯å…¸"é‡Œæœ‰å¤šå°‘ä¸ªè¯ï¼‰å¤§å°å¾ˆé‡è¦ï¼š
  - å¤ªå¤§ï¼šæ¨¡å‹ä¼šå˜å¾—å¾ˆå¤§ï¼Œå¯èƒ½ä¼šå½±å“è¿è¡Œé€Ÿåº¦ã€‚
  - å¤ªå°ï¼šå¯èƒ½æ— æ³•å‡†ç¡®è¡¨è¾¾æ‰€æœ‰éœ€è¦çš„è¯ã€‚

  ä¸‹é¢æ˜¯ä¸€äº›çŸ¥åæ¨¡å‹ä½¿ç”¨çš„åˆ†è¯å™¨åŠå…¶è¯è¡¨å¤§å°ï¼š

<table>
  <tr><th>åˆ†è¯å™¨åç§°</th><th>è¯è¡¨å¤§å°</th><th>æ¥è‡ªå“ªé‡Œ</th></tr>
  <tr><td>yi tokenizer</td><td>64,000</td><td>01ä¸‡ç‰©ï¼ˆä¸­å›½ï¼‰</td></tr>
  <tr><td>qwen2 tokenizer</td><td>151,643</td><td>é˜¿é‡Œäº‘ï¼ˆä¸­å›½ï¼‰</td></tr>
  <tr><td>glm tokenizer</td><td>151,329</td><td>æ™ºè°±AIï¼ˆä¸­å›½ï¼‰</td></tr>
  <tr><td>mistral tokenizer</td><td>32,000</td><td>Mistral AIï¼ˆæ³•å›½ï¼‰</td></tr>
  <tr><td>llama3 tokenizer</td><td>128,000</td><td>Metaï¼ˆç¾å›½ï¼‰</td></tr>
</table>

  æœ¬é¡¹ç›®ä½¿ç”¨äº†ä¸€ä¸ªç›¸å¯¹è¾ƒå°çš„è¯è¡¨ï¼Œè¿™æ ·å¯ä»¥è®©æ¨¡å‹æ›´å°å·§ï¼Œæ›´å®¹æ˜“åœ¨æ™®é€šç”µè„‘ä¸Šè¿è¡Œã€‚

### æ•°æ®é›†ä¸‹è½½åœ°å€

ä¸‹è½½åˆ°`./dataset/`ç›®å½•ä¸‹

| æ•°æ®é›†      | ä¸‹è½½åœ°å€                                                                                                                                                                                                                       |
|--------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **ã€tokenizerè®­ç»ƒé›†ã€‘** | [HuggingFace](https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main) / [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1yAw1LVTftuhQGAC1Y9RdYQ?pwd=6666)                                                                   |
| **ã€Pretrainæ•°æ®ã€‘**   | [Seq-Monkeyå®˜æ–¹](http://share.mobvoi.com:5000/sharing/O91blwPkY)  / [ç™¾åº¦ç½‘ç›˜](https://pan.baidu.com/s/1-Z8Q37lJD4tOKhyBs1D_6Q?pwd=6666) / [HuggingFace](https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main) |
| **ã€SFTæ•°æ®ã€‘**        | [åŒ æ•°å¤§æ¨¡å‹SFTæ•°æ®é›†](https://www.modelscope.cn/datasets/deepctrl/deepctrl-sft-data/resolve/master/sft_data_zh.jsonl)                                                                                                              |
| **ã€DPOæ•°æ®ã€‘**        | [Huggingface](https://huggingface.co/datasets/jingyaogong/minimind_dataset/tree/main/dpo)                                                                                                                                  |

# Model

Denseæ¨¡å‹æ¶æ„ï¼ˆä¸[Llama3.1](https://ai.meta.com/blog/meta-llama-3-1/)ç›¸ä¼¼ï¼‰é‡‡ç”¨äº†Transformerçš„Decoder-Onlyç»“æ„ï¼Œç›¸è¾ƒäºGPT-3æœ‰ä»¥ä¸‹ä¸»è¦åŒºåˆ«ï¼š

* å®ç°äº†Pre-Normalizationï¼šåœ¨æ¯ä¸ªTransformerå­å±‚çš„è¾“å…¥ç«¯åº”ç”¨å½’ä¸€åŒ–ï¼Œè€Œéè¾“å‡ºç«¯ã€‚å…·ä½“ä½¿ç”¨RMSNormï¼ˆRoot Mean Square Layer Normalizationï¼‰ä½œä¸ºå½’ä¸€åŒ–å‡½æ•°ã€‚
* æ¿€æ´»å‡½æ•°é€‰æ‹©ï¼šç”¨SwiGLUï¼ˆSwish-Gated Linear Unitï¼‰æ›¿æ¢äº†ReLUï¼Œä»¥æå‡æ¨¡å‹æ€§èƒ½ã€‚
* ä½ç½®ç¼–ç æ–¹æ¡ˆï¼šæ‘’å¼ƒäº†ç»å¯¹ä½ç½®åµŒå…¥ï¼Œé‡‡ç”¨æ—‹è½¬ä½ç½®ç¼–ç ï¼ˆRotary Position Embedding, RoPEï¼‰ï¼Œè¿™ç§æ–¹æ³•åœ¨å¤„ç†è¶…å‡ºè®­ç»ƒåºåˆ—é•¿åº¦çš„æ¨ç†ä»»åŠ¡æ—¶è¡¨ç°æ›´ä¸ºå‡ºè‰²ã€‚

MoEï¼ˆMixture of Expertsï¼‰æ¨¡å‹æ¶æ„åŸºäº[Deepseek-V2](https://arxiv.org/pdf/2405.04434)ä¸­æå‡ºçš„MixFFNï¼ˆMixed Feed-Forward Networkï¼‰æ··åˆä¸“å®¶æ¨¡å—ï¼š

* DeepSeek-V2åœ¨å‰é¦ˆç½‘ç»œï¼ˆFFNï¼‰å±‚é¢å¼•å…¥äº†æ›´ç»†ç²’åº¦çš„ä¸“å®¶åˆ†å‰²ç­–ç•¥å’Œå…±äº«çš„ä¸“å®¶éš”ç¦»æŠ€æœ¯ï¼Œæ—¨åœ¨æå‡å„ä¸ªExpertçš„æ•ˆèƒ½å’Œæ•´ä½“æ¨¡å‹æ€§èƒ½ã€‚

---

# Experiment

```bash
CPU: Intel(R) Xeon(R) Gold 6248R CPU @ 3.00GHz
å†…å­˜ï¼š256 GB
æ˜¾å¡ï¼šNVIDIA Tesla V100(32GB) * 4
ç¯å¢ƒï¼špython 3.9 + Torch 2.1.2 + DDPå¤šå¡è®­ç»ƒ
```

---

1. **é¢„è®­ç»ƒ(Text-to-Text)**:
    - é¢„è®­ç»ƒé˜¶æ®µæ¨¡å‹ä»å¤§é‡æ–‡æœ¬æ•°æ®ä¸­å­¦ä¹ åŸºç¡€çŸ¥è¯†å’Œè¯­è¨€æ¨¡å¼ã€‚
    - æ•°æ®æ¥æºåŒ…æ‹¬ç»´åŸºç™¾ç§‘ã€æ–°é—»ã€ä¹¦ç±ç­‰å¹¿æ³›é¢†åŸŸã€‚
    - ç›®æ ‡æ˜¯é€šè¿‡æ— ç›‘ç£å­¦ä¹ å‹ç¼©çŸ¥è¯†åˆ°æ¨¡å‹æƒé‡ï¼Œæé«˜ä¸‹ä¸€è¯é¢„æµ‹èƒ½åŠ›ã€‚

    ```bash
    torchrun --nproc_per_node 2 pretrain/pretrain.py
    ```
2. **å•è½®å¯¹è¯æœ‰ç›‘ç£å¾®è°ƒ**:
    - å¯¹é¢„è®­ç»ƒæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶é€‚åº”èŠå¤©æ¨¡æ¿ã€‚
    - é™åˆ¶æ¨¡å‹åœ¨æŒ‡å®šæ ¼å¼å†…ç”Ÿæˆå›å¤ã€‚
    - æŒ‡ä»¤å’Œå›ç­”é•¿åº¦é™åˆ¶ä¸º512 tokensï¼Œä»¥ä¼˜åŒ–èµ„æºä½¿ç”¨ã€‚

   ```bash
   torchrun --nproc_per_node 2 sft/full_sft.py
   ```

3. **å¤šè½®å¯¹è¯å¾®è°ƒ**:
    - åœ¨å•è½®å¯¹è¯åŸºç¡€ä¸Šï¼Œè¿›è¡Œå¤šè½®å¯¹è¯æ¨¡æ¿çš„å¾®è°ƒã€‚
    - ä½¿ç”¨æ•°æ®é›†ä¸­çš„å†å²å¯¹è¯å’Œå›ç­”å­—æ®µæ„å»ºè®­ç»ƒæ ·æœ¬ã€‚
    - æ³¨æ„ï¼šå°æ¨¡å‹åœ¨é•¿ä¸Šä¸‹æ–‡å¯¹è¯ä¸­è¡¨ç°å¯èƒ½ä¸ä½³ã€‚

    ```bash
    torchrun --nproc_per_node 2 sft/full_sft.py
    ```

4. **ç›´æ¥åå¥½ä¼˜åŒ–ï¼ˆDPOï¼‰**:
    - é€šè¿‡å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä¼˜åŒ–æ¨¡å‹è¾“å‡ºä»¥æ›´ç¬¦åˆäººç±»åå¥½ã€‚
    - ä½¿ç”¨æ­£é¢å’Œè´Ÿé¢ç¤ºä¾‹è¿›è¡Œè®­ç»ƒã€‚

    ```bash
    python rlhf/dpo_train.py
    ```

---

# Others

### æ¨ç†ä¸å¯¼å‡º

* [export/export_model.py](export/export_model.py)å¯ä»¥å¯¼å‡ºæ¨¡å‹åˆ°transformersæ ¼å¼ï¼Œæ¨é€åˆ°huggingface

---

### APIæ¨ç†

* [inference/my_openai_api.py](inference/my_openai_api.py)å®Œæˆäº†openai_apiçš„èŠå¤©æ¥å£ï¼Œæ–¹ä¾¿å°†è‡ªå·±çš„æ¨¡å‹æ¥å…¥ç¬¬ä¸‰æ–¹UI
  ä¾‹å¦‚fastgptã€OpenWebUIç­‰

* å¯åŠ¨èŠå¤©æœåŠ¡ç«¯
    ```bash
    python inference/my_openai_api.py
    ```
* æµ‹è¯•æœåŠ¡æ¥å£
    ```bash
    python inference/chat_openai_api.py
    ```
* APIæ¥å£ç¤ºä¾‹ï¼Œå…¼å®¹openai apiæ ¼å¼
    ```bash
    curl http://ip:port/v1/chat/completions \
      -H "Content-Type: application/json" \
      -d '{ 
        "model": "model-identifier",
        "messages": [ 
          { "role": "user", "content": "ä¸–ç•Œä¸Šæœ€é«˜çš„å±±æ˜¯ä»€ä¹ˆï¼Ÿ" }
        ], 
        "temperature": 0.7, 
        "max_tokens": -1,
        "stream": true
    }'
    ```

# Acknowledge

<details close> 
<summary> <b>æ„Ÿè°¢ä»¥ä¸‹ä¼˜ç§€çš„å¼€æºé¡¹ç›®</b> </summary>

- æ’åä¸åˆ†ä»»ä½•å…ˆåé¡ºåº
- [https://github.com/meta-llama/llama3](https://github.com/meta-llama/llama3)
- [https://github.com/karpathy/llama2.c](https://github.com/karpathy/llama2.c)
- [https://github.com/DLLXW/baby-llama2-chinese](https://github.com/DLLXW/baby-llama2-chinese)
- [https://github.com/charent/ChatLM-mini-Chinese](https://github.com/charent/ChatLM-mini-Chinese)
- [https://github.com/wdndev/tiny-llm-zh](https://github.com/wdndev/tiny-llm-zh)
- [https://github.com/Tongjilibo/build_MiniLLM_from_scratch](https://github.com/Tongjilibo/build_MiniLLM_from_scratch)
- [https://github.com/jzhang38/TinyLlama](https://github.com/jzhang38/TinyLlama)
- [https://github.com/AI-Study-Han/Zero-Chatgpt](https://github.com/AI-Study-Han/Zero-Chatgpt)
- [https://github.com/xusenlinzy/api-for-open-llm](https://github.com/xusenlinzy/api-for-open-llm)
- [https://github.com/HqWu-HITCS/Awesome-Chinese-LLM](https://github.com/HqWu-HITCS/Awesome-Chinese-LLM)

</details>


# License

This repository is licensed under the [Apache-2.0 License](LICENSE).


